\begin{figure}
\begin{center}
    \includegraphics[width=0.6\textwidth]{figs/tdist_factor_kmax0_5.pdf} 
    \caption{Ratio of the Fisher matrix for a modified $t$-distribution, 
    $F^{t\mhyphen{\rm dist}}_{ij}$, over the Fisher matrix of the Gaussian 
    pseudo-likelihood, $F^{\rm pseudo}_{ij}$ for the power spectrum multipole 
    ($P_\ell$; left) and the bispectrum ($B_0$; right). The likelihoods for 
    $P_\ell$ and $B_0$ up to $k_{\rm max}$ have 89 and 1898 dimensions 
    respectively. 
    }
\label{fig:f_tdist}
\end{center}
\end{figure}


\section{Fisher Matrix for Modified $t$-distribution Likelihoods} \label{sec:tdist}
The standard approach for Fisher matrix forecasts and parameter inference in LSS 
assumes that the $p$-dimensional likelihood is Gaussian and uses the \cite{hartlap2007} 
factor, 
\beq
f_{\rm Hartlap} = \frac{N-p-2}{N-1}
\eeq
to account for the bias in the inverse covariance matrix $\estC^{-1}$ 
estimated from $N$ mocks. In addition to breaking down on large scales where Central 
Limit Theorem no longer holds~\citep{hahn2019}, this assumption also breaks down 
when the covariance matrix $\bfi{C}$ is estimated from a finite number of 
mocks~\citep{sellentin2016}. In fact, \cite{sellentin2016} show that the likelihood 
is no longer Gaussian but a modified $t$-distribution: 
\beq \label{eq:tdist_like}
p(y \given \mu(\theta), \widehat{\bfi{C}}, N) = 
\frac{c_p}{|\estC|^{1/2}} \left(1+\frac{\left(y-\mu(\theta)\right)^T \estC^{-1} \left(y-\mu(\theta)\right)}{1-N}\right)^{-N/2}.
\eeq
where 
\beq
c_p = \frac{\Gamma(\frac{N}{2})}{[\pi(N-1)]^{p/2} ~\Gamma(\frac{N-p}{2})}, 
\eeq
$\Gamma$ is the Gamma function, $y$ is the data, $\mu$ is our model, and 
$\widehat{\bfi{C}}$ is the estimated covariance matrix. Adopting the wrong 
likelihood, even when the bias of the inverse covariance matrix is accounted 
for,  will yield incorrect posterior distributions with biased parameter 
estimates and incorrect errors~\citep{sellentin2016}. Therefore, we derive 
below the Fisher matrix for the modified $t$-distribution likelihood. We 
follow the derivations from \cite{lange1989} and refer readers to it for 
details. 

Let $\ell(\theta)$ be the log-likelihood, $z = \estC^{-1/2} (y - \mu)$, and 
\beq
g(s) = c_p \left(1+\frac{s}{N-1}\right)^{-N/2}
\eeq
so that Eq.~\ref{eq:tdist_like} can be written as $p(y \given \mu(\theta),\estC,N) = |\estC|^{-1/2} g(||z||^2)$.
Then the derivative of the log-likelihood is  
\beq
\frac{\partial \ell}{\partial \theta_i} = \left(\frac{1}{g}\frac{\partial g}{\partial s}\right) \left(-2 \frac{\partial \mu}{\partial \theta_i}^T \estC^{-1}(y-\mu)\right) 
\eeq
We can write the Fisher matrix as  
\begin{align}
F_{ij} &= - \bigg<\frac{\partial^2 \ell}{\partial \theta_i \partial \theta_j}\bigg>
    = \bigg<\frac{\partial \ell}{\partial \theta_i} \frac{\partial \ell}{\partial \theta_j}\bigg> \\ 
    &= 4\bigg< \left(\frac{1}{g}\frac{\partial g}{\partial s}\right)^2
    \left(z^T\estC^{-1/2}\frac{\partial \mu}{\partial \theta_i} \frac{\partial \mu^T}{\partial \theta_j}\estC^{-1/2} z \right)\bigg>.
    \intertext{Using Lemma 1 from \cite{lange1989}, we get} 
    &= 4\bigg< \left(\frac{1}{g}\frac{\partial g}{\partial s}\right)^2
||z||^2 \left(\frac{z^T}{||z||}\estC^{-1/2}\frac{\partial \mu}{\partial \theta_i} \frac{\partial \mu^T}{\partial \theta_j}\estC^{-1/2}\frac{z}{||z||} \right)\bigg> \\
    &= 4\bigg<||z||^2 \left(\frac{1}{g}\frac{\partial g}{\partial s}\right)^2 \bigg> \frac{1}{p} {\rm Tr}\left(\estC^{-1/2}\frac{\partial \mu}{\partial \theta_i} \frac{\partial \mu^T}{\partial \theta_j}\estC^{-1/2}\right) \\
    &= 4\bigg<||z||^2 \left(\frac{1}{g}\frac{\partial g}{\partial s}\right)^2 \bigg> \frac{1}{p}\frac{\partial \mu^T}{\partial \theta_i}\estC^{-1}\frac{\partial \mu}{\partial \theta_j} \label{eq:app1}
\end{align}
Since
\beq
\frac{1}{g}\frac{\partial g}{\partial s} = -\frac{N}{2} \left(\frac{1}{N-1}\right) \left(1+\frac{s}{N-1}\right)^{-1} 
\eeq
we can expand
\begin{align}
\bigg<||z||^2 \left(\frac{1}{g}\frac{\partial g}{\partial s}\right)^2 \bigg> 
    &= \bigg<||z||^2 \frac{N^2}{4} \left(\frac{1}{N-1}\right)^2 \left(1+\frac{s}{N-1}\right)^{-2} \bigg> \\ 
    &= \frac{N^2}{4(N-1)}\bigg<\frac{||z||^2}{N-1} \left(1+\frac{||z||^2}{N-1}\right)^{-2} \bigg> \\
    &= \frac{N^2}{4(N-1)} \int\limits_0^\infty A_p \left(\frac{s^2}{N-1}\right) 
    \left(1 + \frac{s^2}{N-1}\right)^{-2}
    c_p\left(1 + \frac{s^2}{N-1}\right)^{-\frac{N}{2}} s^{p-1} {\rm d}s \\
    \intertext{where $A_p$ is the surface area of the unit sphere in $\mathbb{R}$. Evaluating the integral we get}
    &= \frac{N^2}{4(N-1)}\bigg[\frac{2 \pi^{\frac{p}{2}}c_p}{(N-1)\Gamma(\frac{p}{2})} \frac{(N-1)^{\frac{p}{2}+1}}{2} B\left(\frac{p}{2}, \frac{N-p+2}{2}\right)\bigg].  
    \intertext{where $B$ is the beta function. Expanding this expression we get}
    &= \frac{p(N-p)N}{4 (N-1)(N+2)} 
\end{align}
Plugging the expression back into Eq.~\ref{eq:app1}, we get the Fisher matrix for the modified $t$-distribution: 
\beq
F^{t\mhyphen{\rm dist}}_{ij} = \frac{N(N-p)}{(N-1)(N+2)}\frac{\partial \mu^T}{\partial \theta_i}\estC^{-1}\frac{\partial \mu}{\partial \theta_j} 
= f_{t\mhyphen{\rm dist}} \widehat{F_{ij}}.
\eeq
In contrast, the Fisher matrix for the Gaussian pseudo-likelihood is 
\beq
F^{\rm pseudo}_{ij} = \frac{N-p-2}{N-1}\frac{\partial \mu^T}{\partial \theta_i}\estC^{-1}\frac{\partial \mu}{\partial \theta_j}
= f_{\rm Hartlap} \widehat{F_{ij}}.
\eeq
For a $p{=}79$ dimensional likelihood ($P_\ell$ likelihood for $k_{\rm max} = 0.5$) 
$f_{t\mhyphen{\rm dist}} > f_{\rm Hartlap}$ for $N \le 81$ 
and $f_{t\mhyphen{\rm dist}} < f_{\rm Hartlap}$ for $N > 81$. For a $p{=}428$ 
dimionsional likelihood ($B_0$ likelihood for $k_{\rm max} = 0.5$), 
$f_{t\mhyphen{\rm dist}} > f_{\rm Hartlap}$ for $N \le 697$ and 
$f_{t\mhyphen{\rm dist}} < f_{\rm Hartlap}$ for $N > 697$. As the number of mocks 
increases, both $f_{t\mhyphen{\rm dist}}$ and $f_{\rm Hartlap}$ converge to 1. 
We note that although the likelihood $p(y \given \mu(\theta),\estC,N)$ is a 
function of $N$, we do not explicitly marginalize over it. This is because as 
\cite{lange1989} proves, the Fisher matrix for a $t$-disttribution is block 
diagonal --- \emph{i.e.} $F_{\theta_i, N} = 0$ and $F_{\theta_j, N} = 0$. 
Hence, $N$ does not impact our Fisher forecasts constraints for cosmological 
parameters. 

%Hartlap et al. (2007) argue that this debiased inverse covariance matrix will remove all biases from parameter inference. However, the situation is more complex. In a Bayesian analysis one would not necessarily define an estimator θˆ, but if one does, the bias is bθ = ⟨θˆ ⟩ − θ , where the angular brackets now denote the average over the likelihood of the parameters. Adopting the wrong sampling distribution will yield incorrect posterior distributions, with biased parameter estimates (should they be made) and incorrect errors, even if the inverse covariance matrix itself has been debiased.

